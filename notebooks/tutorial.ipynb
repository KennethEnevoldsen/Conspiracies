{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd01480ab772fc411d7ca1727d09e832fe7601f5cc4f8124433fde8367620a21b72",
   "display_name": "Python 3.9.1 64-bit ('conspiracies': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Open Knowledge Graph Tutorial\n",
    "\n",
    "This short notebook will run through an example use case of  `belief_graph` for automatic construction of an open knowledge graph. Some of the main functionalities of `belief_graph` will be covered, but this tutorial is not extensive. \n",
    "\n",
    "We will use the Twitter part of the [Danish Gigaword Corpus](https://gigaword.dk) for this exploratory analysis. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import belief_graph as bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and extract text to list"
   ]
  },
  {
   "source": [
    "# First off, let's load the Spacy nlp pipeline\n",
    "\n",
    "# load_danish() is a helper method that loads the Danish_news_sm pipeline with the Danish Electra transformer model\n",
    "nlp = bg.load_danish()\n",
    "\n",
    "# Now, instantiate the BeliefParser which parses the texts and returns BeliefTriplets. These consist of a head word(s), tail word(s), and their relation (e.g. h: Mette Frederiksen, r: er, t: statsminister)\n",
    "bp = bg.BeliefParser(nlp=nlp)\n",
    "\n",
    "# BeliefGraph is used to gather the BeliefTriplets into a graph. Once in the graph, we can do all sorts of interesting network analysis, or plot specific nodes and its relations\n",
    "graph = bg.BeliefGraph(parser=bp)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Now with everything set up, we are ready to add texts to the pipeline."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_texts(tweet_list)\n"
   ]
  },
  {
   "source": [
    "The relations we have extracted now are very noisy - let's see an example."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.plot_node(nodes = \"Mette Frederiksen\")"
   ]
  },
  {
   "source": [
    "To handle this, `belief_graph` includes the following filters:\n",
    "\n",
    "- ConfidenceFilter: filter by how confident the model is   \n",
    "- ContinuousFilter: only includes words that appear continuously\n",
    "- CountFilter: require nodes to appear a certain number of times in the corpus\n",
    "- DepFilter: include/exclude specific terms from a dependency parsing\n",
    "- EntFilter: include/exclude specific named entities (LOC, PERS, ORG, MISC in Danish)\n",
    "- PosFilter: include/exclude specific Parts-of-Speech tags\n",
    "- LemmatizationFilter: use lemmas instead of tokens\n",
    "\n",
    "These can be mixed and matched as you see fit. Let's see the effect of setting a confidence threshold and only including nodes that have the LOC or PERS tag."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESHOLD = 0.85\n",
    "conf_filter = bg.filters.ConfidenceFilter(threshold=CONF_THRESHOLD)\n",
    "\n",
    "VALID_ENTITIES={\"LOC\", \"PERS\"}\n",
    "ent_filter = bg.filters.EntFilter(valid=VALID_ENTITIES)\n",
    "\n",
    "# To update the graph we pass the filters as a list\n",
    "filters = [conf_filter, ent_filter]\n",
    "\n",
    "graph.replace_filters(triplet_filters=filters)\n",
    "\n",
    "# Let's see how the network has changed\n",
    "graph.plot_node(nodes = \"Mette Frederiksen\")"
   ]
  },
  {
   "source": [
    "You can plot networks for multiple nodes by passing a list of node names to the `nodes` parameter in `graph.plot_node`. Similarly, it is easy to change filters: simply create the ones you want, and run `graph.replace_filters` with your updated filter list. \n",
    "\n",
    "If you pass the keyword \"all\" to `nodes` the network will include all nodes in the graph. This is especially useful in combination with `return_graph=True`, as this returns the networkx graph. With this, you can explore the entire network and calculate various measures such as centrality, degree, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = graph.plot_node(nodes = \"all\", return_graph=True)\n",
    "\n",
    "network.G"
   ]
  }
 ]
}